{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riccardo/anaconda3/envs/siv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "from model.SiameseReId import SiameseReId\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8n-seg.pt\") # COCO128 classes https://github.com/ultralytics/yolov5/blob/master/data/coco128.yaml\n",
    "# model = YOLO(\"yolov8n-seg.pt\")\n",
    "siamese_net = SiameseReId(os.path.join('model','weights','model_final.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_segmentation(segment,box,image):\n",
    "    img = image.copy()\n",
    "    box = box.astype(int)\n",
    "    w,h,c = img.shape\n",
    "    mask = (cv2.resize(segment,(h,w)) > 0).astype(\"uint8\")\n",
    "    img_segm = cv2.bitwise_and(img,img,mask=mask)\n",
    "    img_segm = img_segm[box[1]:box[3],box[0]:box[2]]\n",
    "    return cv2.cvtColor(img_segm, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing sliding window "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "file_path = 'test_scout.mp4'\n",
    "cap = cv2.VideoCapture(file_path)\n",
    "video_out = cv2.VideoWriter(\"./out.mp4\", cv2.VideoWriter_fourcc(*'DIVX'), int(cap.get(cv2.CAP_PROP_FPS)), (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "# set initial circular buffer index to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fv</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [fv, color]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialized track_id array\n",
    "track_id_df = pd.DataFrame(columns=['fv','color'])\n",
    "track_id_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1920, 1080)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get video resolution\n",
    "vid_w, vid_h = int(cap.get(3)), int(cap.get(4))\n",
    "vid_w, vid_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_window = 10\n",
    "# generate a circular buffer for video frame(frame_window)\n",
    "buffer_frames = np.zeros((frames_window,vid_h, vid_w,3),dtype=\"uint8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate circular buffer with frame\n",
    "while i < frames_window:\n",
    "    ret, frame = cap.read()\n",
    "    buffer_frames[i] = frame.copy()\n",
    "    i+=1\n",
    "    if not ret:\n",
    "        cap.release()\n",
    "        video_out.release()\n",
    "        quit() #kill the program\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detections array associated to frames\n",
    "buffer_detections = [None]*frames_window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 persons, 1 frisbee, 11.1ms\n",
      "Speed: 13.7ms pre-process, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bench, 1 frisbee, 1 sports ball, 10.1ms\n",
      "Speed: 0.3ms pre-process, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bench, 1 frisbee, 7.7ms\n",
      "Speed: 0.3ms pre-process, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bench, 1 frisbee, 1 sports ball, 7.6ms\n",
      "Speed: 0.3ms pre-process, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bench, 1 sports ball, 7.7ms\n",
      "Speed: 0.3ms pre-process, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bench, 9.5ms\n",
      "Speed: 0.3ms pre-process, 9.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bench, 7.7ms\n",
      "Speed: 0.3ms pre-process, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bench, 1 frisbee, 7.6ms\n",
      "Speed: 0.3ms pre-process, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bench, 1 frisbee, 7.6ms\n",
      "Speed: 0.3ms pre-process, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bench, 1 frisbee, 7.6ms\n",
      "Speed: 0.3ms pre-process, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "# TODO: exec only on second half of buffer, in the first simply reset datframe extra values\n",
    "# make prediction for each frame in the buffer\n",
    "for frame_id in range(frames_window):\n",
    "    # deep copy of frame image (yolo draw on the predicted image)\n",
    "    frame_copy = deepcopy(buffer_frames[frame_id])\n",
    "\n",
    "    # get results and convert to numpy\n",
    "    results = model.predict(frame_copy)[0].cpu().numpy()\n",
    "\n",
    "    # filter prediction of class person with conf > 0.5\n",
    "    idx = np.where((results.boxes.cls == 0) & (\n",
    "        results.boxes.conf > 0.6))  # filter person\n",
    "\n",
    "    # extract masks,boxes and bb centers\n",
    "    masks = results.masks.masks[idx].copy()\n",
    "    boxes = results.boxes.xyxy[idx].copy()\n",
    "    centers = results.boxes.xywh[idx][:, :2].copy().astype(int)\n",
    "\n",
    "    # populate detection array with associeted detections\n",
    "    buffer_detections[frame_id] = pd.DataFrame({\n",
    "                                            'box': boxes.tolist(),\n",
    "                                            'mask': masks.tolist(),\n",
    "                                            'center': centers.tolist(),\n",
    "                                            'box_id': np.full(len(idx[0]), -1).tolist(),\n",
    "                                            'track_id': np.full(len(idx[0]), -1).tolist()\n",
    "                                            })\n",
    "\n",
    "    # delete yolo drawed frame\n",
    "    del frame_copy, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the max detections number in per frame\n",
    "cluster_numbers = max([len(j) for j in buffer_detections])\n",
    "cluster_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list containing all the detections per frame\n",
    "centers = []\n",
    "\n",
    "for j in buffer_detections:\n",
    "    for val in j['center'].values:\n",
    "        centers.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit kmeans cluster with n_cluster equal to max detections per frame\n",
    "kmeans = KMeans(n_clusters=cluster_numbers, random_state=0, n_init=\"auto\").fit(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each detections find the box number\n",
    "for det in buffer_detections:\n",
    "    det['box_id'] = det['center'].apply(lambda x: kmeans.predict(np.array([x]).tolist())[0])\n",
    "\n",
    "del cluster_numbers, centers, kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get tid given the detection image [return -1 if no similarity find]\n",
    "def get_tid(track_id_df,det_img):\n",
    "    similarity = track_id_df['fv'].apply(lambda x: siamese_net.similarity(det_img,torch.tensor(x)).detach().cpu().numpy()[0][0])\n",
    "    if similarity.empty:\n",
    "        return -1\n",
    "    else:\n",
    "        return similarity.idxmax() if similarity.loc[similarity.idxmax()] > 0.8 else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each detection calculate feature vector and the correspondent track_id [-1 if no similarity found]\n",
    "for i,det in enumerate(buffer_detections):\n",
    "    det['fv'] = det.apply(lambda x: siamese_net.fv_encoding(Image.fromarray(crop_segmentation(np.array(x['mask']),np.array(x['box']),buffer_frames[i]))).cpu().numpy(),axis=1)\n",
    "    det['track_id'] = det.apply(lambda x: get_tid(track_id_df,Image.fromarray(crop_segmentation(np.array(x['mask']),np.array(x['box']),buffer_frames[i]))),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each detection id get the frame_window tid prediction\n",
    "counter = {}\n",
    "\n",
    "for i,det in enumerate(buffer_detections):\n",
    "    for index, row in det.iterrows():\n",
    "        tmp_box_id = row['box_id']\n",
    "        if str(tmp_box_id) not in counter:\n",
    "            counter[str(tmp_box_id)] = [row['track_id']]\n",
    "        else:\n",
    "            counter[str(tmp_box_id)].append(row['track_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each detection count the occurence of tid associeted, if < 3 return None (not valid)\n",
    "for key in counter:\n",
    "    # counter[key] = max(counter[key],key=counter[key].count)\n",
    "    counting_inst = {str(u):counter[key].count(u) for u in np.unique(np.array(counter[key]))}\n",
    "    candidate_tid = max(counting_inst,key=counting_inst.get)\n",
    "    tid = candidate_tid if counting_inst[candidate_tid] >= int(frames_window*.8) else None\n",
    "    counter[key] = tid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used = []\n",
    "# implement filter on duplicate tid\n",
    "for id in counter:\n",
    "    if counter[id] is not None: #if None don't evaluate\n",
    "        if int(counter[id]) != -1: #ignore -1 (to add)\n",
    "            if counter[id] not in used:\n",
    "                used.append(counter[id])\n",
    "            else:\n",
    "                counter[id] = None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each detection, set the processed tid\n",
    "for det in buffer_detections:\n",
    "    det['track_id'] = det['box_id'].apply(lambda x: counter[str(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "del counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "added = {}\n",
    "for det in buffer_detections:\n",
    "    for index, row in det.iterrows():\n",
    "        if row['track_id'] is not None:\n",
    "            if int(row['track_id']) == -1:\n",
    "                if row['box_id'] not in added:\n",
    "                    # add fv to track_id and return last index\n",
    "                    color = np.random.randint(0,255,3).tolist()\n",
    "                    track_id_df = pd.concat([track_id_df, pd.DataFrame({\"fv\": [row['fv']], 'color':[color]})], ignore_index=True)\n",
    "                    new_tid = track_id_df.index[-1]\n",
    "                    added[row['box_id']] = new_tid\n",
    "                    det._set_value(index,'track_id',new_tid)\n",
    "                    row['track_id'] = new_tid\n",
    "                    print(f\"aggiunto {row['box_id']}\")\n",
    "                else:\n",
    "                    det._set_value(index,'track_id',added[row['box_id']])\n",
    "                    row['track_id'] = added[row['box_id']]\n",
    "\n",
    "            # track_id_df.loc[int(row['track_id'])]['fv'] = row['fv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "del added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fv</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[110, 193, 166]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[249, 22, 134]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[184, 225, 75]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  fv            color\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  [110, 193, 166]\n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   [249, 22, 134]\n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   [184, 225, 75]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_id_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in range(frames_window//2):\n",
    "    drew_frame = buffer_frames[f].copy()\n",
    "    for indx, row in buffer_detections[f].iterrows():\n",
    "        if row['track_id'] is not None:\n",
    "            color = track_id_df.loc[int(row['track_id'])]['color']\n",
    "            drew_frame = cv2.rectangle(drew_frame, (int(row['box'][0]), int(row['box'][1])), (int(row['box'][2]), int(row['box'][3])), color, 3)\n",
    "            drew_frame = cv2.putText(drew_frame, str(row['track_id']), (int(row['box'][0]),int(row['box'][1])), cv2.FONT_HERSHEY_SIMPLEX, 1.5, color, 2, cv2.LINE_AA)\n",
    "        else:\n",
    "            color = (255,255,255)\n",
    "            drew_frame = cv2.rectangle(drew_frame, (int(row['box'][0]), int(row['box'][1])), (int(row['box'][2]), int(row['box'][3])), color, 3)\n",
    "\n",
    "    cv2.imwrite(f\"./prova/{time.time()}.jpg\", drew_frame)\n",
    "    video_out.write(drew_frame.copy())\n",
    "    del drew_frame\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f_swap in range(frames_window//2):\n",
    "    buffer_frames[f_swap] = buffer_frames[f_swap+frames_window//2] \n",
    "\n",
    "i = frames_window//2\n",
    "\n",
    "# frame_n += frames_window//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('siv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c9c71ba83d9509be3e641d0bfc3c2b4ff64c3d1f38dab0db17242b2063feac14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
