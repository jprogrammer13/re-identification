{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "import sklearn\n",
    "import torch\n",
    "\n",
    "import progressbar"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from video_handler.VideoHandler import VideoHandler\n",
    "from detection.Detection import Detection\n",
    "from model.SiameseReId import SiameseReId"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "video_path = \"test.mp4\"\n",
    "n_frames = 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "__video_handler: VideoHandler = VideoHandler(video_path)\n",
    "__detection: Detection = Detection()\n",
    "__siamese_net: SiameseReId = SiameseReId(\"./model/weights/model_final.pt\")\n",
    "__features: pd.DataFrame = pd.DataFrame(columns=[\"fv\", \"color\"])\n",
    "__vid_w, __vid_h, video_frame_count = __video_handler.get_video_w_h_fc()\n",
    "\n",
    "__frame_count: int = video_frame_count\n",
    "\n",
    "if n_frames != -1:\n",
    "    if n_frames <= video_frame_count:\n",
    "        __frame_count = n_frames\n",
    "    else:\n",
    "        sys.exit(f\"Error: \"\n",
    "                 f\"The number of frames ({n_frames}) has to be \"\n",
    "                 f\"less or equal than the number of frames \"\n",
    "                 f\"of the video (for {video_path}: {video_frame_count})\"\n",
    "                 f\"\")\n",
    "\n",
    "# TODO: testare e nel caso mettere fix\n",
    "__batch_size: int = np.array([np.gcd(i, __frame_count) for i in range(5, 11)]).max()\n",
    "print(\"Batch size: \", __batch_size)\n",
    "print(\"Frames count \", __frame_count)\n",
    "\n",
    "if __batch_size < 5:\n",
    "    sys.exit(f\"Error generating batch size with frame number = {__frame_count}\")\n",
    "\n",
    "__frames_buffer: list[np.ndarray] = [np.zeros((__vid_h, __vid_w, 3), dtype=\"uint8\")] * __batch_size\n",
    "__detections_buffer: list[pd.DataFrame] = [None] * __batch_size\n",
    "\n",
    "__counter = {}\n",
    "\n",
    "widgets = [' [',\n",
    "           progressbar.Timer(format='elapsed time: %(elapsed)s'),\n",
    "           '] ',\n",
    "           progressbar.Bar('*'), ' (',\n",
    "           progressbar.ETA(), \") \\n\",\n",
    "           ]\n",
    "__progress_bar: progressbar.ProgressBar = progressbar.ProgressBar(max_value=__frame_count, widgets=widgets).start()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def __get_buffer_frames(buffer_head: int) -> bool:\n",
    "    buffer_id = buffer_head\n",
    "    while buffer_id < __batch_size:\n",
    "        ret, frame = __video_handler.video_read_frame()\n",
    "        if not ret:\n",
    "            return ret\n",
    "        __frames_buffer[buffer_id] = frame.copy()  # TODO copy si o no?\n",
    "        buffer_id += 1\n",
    "    return True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "buffer_head = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "__get_buffer_frames(buffer_head)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for frame in __frames_buffer:\n",
    "    display(Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# detections for frames in frames_buffer\n",
    "__detections_buffer[buffer_head:__batch_size] = \\\n",
    "    __detection.get_segmentation_list_of_dataframes(\n",
    "        __frames_buffer[buffer_head:__batch_size]\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "__detections_buffer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def __get_kmeans_model(max_bb: int) -> sklearn.cluster._kmeans.KMeans:\n",
    "    centers = np.array([])\n",
    "    for det in __detections_buffer:\n",
    "        if not np.any(centers):\n",
    "            centers = det[\"center\"]\n",
    "        else:\n",
    "            centers = pd.concat((centers, det[\"center\"]), axis=0)\n",
    "\n",
    "    # fit kmeans cluster with n_cluster equal to max detections per frame\n",
    "    return KMeans(n_clusters=max_bb, random_state=0, n_init=\"auto\").fit(centers.tolist())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def __find_box_id() -> None:\n",
    "    # len of bounding boxes dataframe per frame\n",
    "    max_bb_in_batch = max([len(frame_bb) for frame_bb in __detections_buffer])\n",
    "    if max_bb_in_batch > 0:  # at least one frame with persons\n",
    "        kmeans = __get_kmeans_model(max_bb_in_batch)\n",
    "\n",
    "        for df in __detections_buffer:\n",
    "            df[\"box_id\"] = df[\"center\"].apply(lambda row: kmeans.predict([np.array(row)]).tolist()[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "__find_box_id()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "__detections_buffer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def __get_track_id_of_detection_img(img: Image) -> int:\n",
    "    similarity = __features['fv'].apply(lambda x: __siamese_net.similarity(\n",
    "        img, torch.tensor(x)).detach().cpu().numpy()[0][0])\n",
    "    if similarity.empty:\n",
    "        return -1\n",
    "    else:\n",
    "        return similarity.idxmax() if similarity.loc[similarity.idxmax()] > 0.8 else -1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def __crop_segmentation(mask: list, box: list, img: np.ndarray) -> Image:\n",
    "    # img = img.copy()\n",
    "    w, h, _ = img.shape\n",
    "    mask = (cv2.resize(np.array(mask), (h, w)) > 0).astype(\"uint8\")\n",
    "    img_segm = cv2.bitwise_and(img, img, mask=mask)\n",
    "    img_segm = img_segm[box[1]:box[3], box[0]:box[2]]\n",
    "    return Image.fromarray(cv2.cvtColor(img_segm, cv2.COLOR_BGR2RGB))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def __calculate_features_vectors(buffer_head: int) -> None:\n",
    "    for i, det in enumerate(__detections_buffer):\n",
    "        if not det.empty:\n",
    "            det[\"track_id\"] = det.apply(\n",
    "                lambda row: __get_track_id_of_detection_img(\n",
    "                    __crop_segmentation(row[\"mask\"], row[\"xyxy\"], __frames_buffer[i])\n",
    "                )\n",
    "                if row[\"track_id\"] is not None and int(row[\"track_id\"]) == -1\n",
    "                else row[\"track_id\"],\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "            if i >= buffer_head:\n",
    "                det[\"fv\"] = det.apply(\n",
    "                    lambda row: __siamese_net.fv_encoding(\n",
    "                        __crop_segmentation(row[\"mask\"], row[\"xyxy\"], __frames_buffer[i])\n",
    "                    ).cpu().numpy(),\n",
    "                    axis=1\n",
    "                )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "__calculate_features_vectors(buffer_head)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "__detections_buffer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def __update_counter(box_id: int, track_id: int):\n",
    "    # print(box_id, track_id)\n",
    "    __counter.setdefault(str(box_id), []).append(track_id)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def __count_box_ids() :\n",
    "    for i, det in enumerate(__detections_buffer):\n",
    "        if not det.empty:\n",
    "            det.apply(lambda row: __update_counter(row[\"box_id\"], row[\"track_id\"]), axis=1)\n",
    "\n",
    "    used = set()\n",
    "\n",
    "    for key in __counter:\n",
    "        counting_inst = {str(u): __counter[key].count(u) for u in np.unique(np.array(__counter[key]))}\n",
    "        candidate_tid = max(counting_inst, key=counting_inst.get)\n",
    "        tid = candidate_tid if counting_inst[candidate_tid] >= (__batch_size // 2) else None\n",
    "        __counter[key] = tid\n",
    "        # if None don't evaluate & ignore -1 (to add)\n",
    "        if tid is not None and int(tid) != -1:\n",
    "            if tid not in used:\n",
    "                __counter[key] = tid\n",
    "                used.add(__counter[key])\n",
    "            else:\n",
    "                __counter[key] = None\n",
    "\n",
    "    for det in __detections_buffer:\n",
    "        det['track_id'] = det['box_id'].apply(lambda row: __counter[str(row)])\n",
    "\n",
    "    # __counter = {}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "__count_box_ids()\n",
    "__counter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "__detections_buffer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def __add_features_vectors():\n",
    "    __features2 = pd.DataFrame(columns=[\"fv\", \"color\"])\n",
    "    added = {}\n",
    "\n",
    "    for det in __detections_buffer:\n",
    "        for index, row in det.iterrows():  # doesn't loop on empty datasets\n",
    "            if row[\"track_id\"] == -1:  # not None\n",
    "                if row[\"box_id\"] not in added:\n",
    "                    color = np.random.randint(0, 255, 3).tolist()\n",
    "                    __features2 = pd.concat(\n",
    "                        [__features2, pd.DataFrame({\"fv\": [row['fv']], 'color': [color]})],\n",
    "                        ignore_index=True\n",
    "                    )\n",
    "                    new_tid = __features.index[-1]\n",
    "                    added[row['box_id']] = new_tid\n",
    "                    det._set_value(index, 'track_id', new_tid)\n",
    "                    row[\"track_id\"] = new_tid\n",
    "                else:\n",
    "                    det._set_value(index, 'track_id', added[row['box_id']])\n",
    "                    row[\"track_id\"] = added[row[\"box_id\"]]\n",
    "\n",
    "    pd.concat([__features, __features2], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "__add_features_vectors()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "__detections_buffer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "__features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def __buffers_swap(head: int) -> None:\n",
    "    __frames_buffer[:head] = __frames_buffer[head:]\n",
    "    __detections_buffer[:head] = __detections_buffer[head:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def __draw_video_frames() -> None:\n",
    "    for i in range(__batch_size // 2):\n",
    "        det = __detections_buffer[i]\n",
    "        drew_frame = __frames_buffer[i]\n",
    "        if not det.empty:\n",
    "            for _, row in det.iterrows():\n",
    "                color = (255, 255, 255)\n",
    "                text = \"Unkown\"\n",
    "\n",
    "                if row[\"track_id\"] is not None and int(row[\"track_id\"]) != -1:\n",
    "                    color = __features.loc[int(row[\"track_id\"])][\"color\"]\n",
    "                    text = str(row[\"track_id\"])\n",
    "\n",
    "                drew_frame = __video_handler.frame_draw_info(drew_frame, row[\"xyxy\"], color, text)\n",
    "\n",
    "        __video_handler.video_write(drew_frame)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def __clean_detections_box_ids_track_ids():\n",
    "    for det in __detections_buffer:\n",
    "        det[\"box_id\"] = [-1] * len(det[\"box_id\"])\n",
    "        det.loc[np.where(det[\"track_id\"] == None)[0], \"track_id\"] = -1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "buffer_head = 0\n",
    "frame_nr = 0\n",
    "\n",
    "while frame_nr < __frame_count:\n",
    "    print(frame_nr)\n",
    "    # buffer_id = buffer_head\n",
    "\n",
    "    # initial frames buffer\n",
    "    ret = __get_buffer_frames(buffer_head)\n",
    "\n",
    "    # detections for frames in frames_buffer\n",
    "    __detections_buffer[buffer_head:__batch_size] = \\\n",
    "        __detection.get_segmentation_list_of_dataframes(\n",
    "            __frames_buffer[buffer_head:__batch_size]\n",
    "        )\n",
    "\n",
    "    __find_box_id()\n",
    "\n",
    "    __calculate_features_vectors(buffer_head)\n",
    "\n",
    "    __count_box_ids()\n",
    "\n",
    "    __add_features_vectors()\n",
    "\n",
    "    # draw detections\n",
    "    __draw_video_frames()\n",
    "\n",
    "    # clean detection processing\n",
    "    __clean_detections_box_ids_track_ids()\n",
    "\n",
    "    # circulate circular buffers\n",
    "    __buffers_swap(__batch_size // 2)\n",
    "\n",
    "    # increment indexes\n",
    "    buffer_head = (__batch_size // 2)\n",
    "    frame_nr += (__batch_size // 2)\n",
    "    __progress_bar.update(frame_nr)\n",
    "\n",
    "    if not ret:\n",
    "        __video_handler.set_last_frame()\n",
    "        break\n",
    "\n",
    "__video_handler.release()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
