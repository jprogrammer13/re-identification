{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from model.SiameseReId import SiameseReId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8s.pt\") # COCO128 classes https://github.com/ultralytics/yolov5/blob/master/data/coco128.yaml\n",
    "# model = YOLO(\"yolov8n-seg.pt\")\n",
    "siamese_net = SiameseReId(os.path.join('model','weights','model_final.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def detection(frames: np.array, should_save: bool = False) -> dict:\n",
    "#     results = model(deepcopy(frames), save=should_save)\n",
    "#     detected = {}\n",
    "#\n",
    "#     for frame in range(len(results)):\n",
    "#         # print(frame, results[frame].boxes.numpy(), results[frame].boxes.cls)\n",
    "#         boxes = results[frame].boxes\n",
    "#         detected[frame] = []\n",
    "#         for box in boxes:\n",
    "#             box = box.cpu().numpy()\n",
    "#             # print(box, box.cls, box.conf)\n",
    "#             if int(box.cls[0]) == 0 and box.conf[0] > 0.6:\n",
    "#                 detected[frame].append({\n",
    "#                     \"xyxy\": box.xyxy,\n",
    "#                     \"xywh\": box.xywh,\n",
    "#                     \"conf\": box.conf[0],\n",
    "#                     \"center\": box.xywh[0][0:2]\n",
    "#                 })\n",
    "#         # print('\\n')\n",
    "#     return detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def distance(point1: np.array, point2: np.array) -> float:\n",
    "#     return np.linalg.norm(point1 - point2)\n",
    "\n",
    "# def is_closer_enough(dist: float, epsilon: float = 30) -> bool:\n",
    "#     return dist <= epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def mean_bbox(frames: dict) -> dict:\n",
    "#     same_bb = []\n",
    "#     mean_bb = []\n",
    "#\n",
    "#     if len(frames) > 1:\n",
    "#         for bbox0 in frames[0]: # bbox nel frame 0\n",
    "#             same_bb.append([])\n",
    "#             same_bb[-1].append(bbox0)\n",
    "#             # print(same_bbox)\n",
    "#             # print(\"0: \", bbox0[\"center\"])\n",
    "#\n",
    "#             for bbox1 in frames[1]: # bbox nel frame 1\n",
    "#                 # print(\"\\t1: \", bbox1[\"center\"], \"DIST: \", distance(bbox0[\"center\"], bbox1[\"center\"]))\n",
    "#                 if is_closer_enough(distance(bbox0[\"center\"], bbox1[\"center\"])): # bbox0 <-> bbox1\n",
    "#                     same_bb[-1].append(bbox1)\n",
    "#                     # print(\"FOUND IT \\t1: \", bbox1[\"center\"])\n",
    "#\n",
    "#             for bbox2 in frames[2]: # bbox nel frame 2\n",
    "#                 # print(\"\\t2: \", bbox2[\"center\"], \"DIST: \", distance(same_bbox[-1][-1][\"center\"], bbox2[\"center\"]))\n",
    "#                 if is_closer_enough(distance(same_bb[-1][-1][\"center\"], bbox2[\"center\"])): # (bbox1 or bbox0) <-> bbox2\n",
    "#                     same_bb[-1].append(bbox2)\n",
    "#                     # print(\"FOUND IT \\t2: \", bbox2[\"center\"])\n",
    "#\n",
    "#         for bboxes in same_bb:\n",
    "#             bbs = {\n",
    "#                 \"xyxy\": np.mean(np.array([frame[\"xyxy\"] for frame in bboxes]), axis=0),\n",
    "#                 \"xywh\": np.mean(np.array([frame[\"xywh\"] for frame in bboxes]), axis=0),\n",
    "#                 \"conf\": np.mean(np.array([frame[\"conf\"] for frame in bboxes])),\n",
    "#                 \"center\": np.mean(np.array([frame[\"center\"] for frame in bboxes]), axis=0),\n",
    "#             }\n",
    "#             # print([frame[\"xyxy\"] for frame in bboxes])\n",
    "#             # mean_bb.append(np.mean(np.array([frame[\"xyxy\"] for frame in bboxes]), axis=0))\n",
    "#             mean_bb.append(bbs)\n",
    "#     else:\n",
    "#         for bbox0 in frames[0]:\n",
    "#             mean_bb.append({\n",
    "#                 \"xyxy\": bbox0[\"xyxy\"],\n",
    "#                 \"xywh\": bbox0[\"xywh\"],\n",
    "#                 \"conf\": bbox0[\"conf\"],\n",
    "#                 \"center\": bbox0[\"center\"],\n",
    "#             })\n",
    "#\n",
    "#     return mean_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from video_handler.VideoHandler import VideoHandler\n",
    "from detection.Detection import Detection\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "video_handler = VideoHandler(\"test.mp4\")\n",
    "vid_w, vid_h, frame_count = video_handler.get_video_w_h_fc()\n",
    "\n",
    "detection = Detection()\n",
    "\n",
    "rnd = 0\n",
    "\n",
    "while rnd < 10:\n",
    "    ret, frame = video_handler.video_read_frame()\n",
    "\n",
    "    det = detection.get_segmentation_dict([frame])\n",
    "\n",
    "    drew_frame = frame.copy()\n",
    "    # display(Image.fromarray(cv2.cvtColor(drew_frame, cv2.COLOR_BGR2RGB)))\n",
    "\n",
    "    for i in range(len(det[0])):\n",
    "        color = np.random.randint(0,255,3).tolist()\n",
    "        \n",
    "        # print(det[0][i])\n",
    "        drew_frame = video_handler.frame_draw_info(\n",
    "            drew_frame,\n",
    "            det[0][i][\"xyxy\"].astype(int),\n",
    "            color,\n",
    "            str(i)\n",
    "        )\n",
    "\n",
    "    # video_handler.video_write(drew_frame)\n",
    "\n",
    "    display(Image.fromarray(cv2.cvtColor(drew_frame, cv2.COLOR_BGR2RGB)))\n",
    "\n",
    "    rnd += 1\n",
    "\n",
    "    if ret:\n",
    "        # cv2.imshow(window_name, frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        video_handler.set_last_frame()\n",
    "        break\n",
    "\n",
    "video_handler.release()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_path = 'test.mp4'\n",
    "delay = 1\n",
    "window_name = 'frame'\n",
    "\n",
    "cap = cv2.VideoCapture(file_path)\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    sys.exit()\n",
    "\n",
    "count = 3\n",
    "# frames = []\n",
    "round = 0\n",
    "\n",
    "video_out = cv2.VideoWriter(\"./video_output.mp4\", cv2.VideoWriter_fourcc(*'DIVX'), int(cap.get(cv2.CAP_PROP_FPS)), (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "features = pd.DataFrame(columns=[\"features\",\"color\"])\n",
    "# similarities = pd.DataFrame(columns=[\"track_id\", \"prob\"])\n",
    "\n",
    "while round < 1:\n",
    "# while True:\n",
    "    reads = [cap.read() for i in range(count)] # [(True, [...]] if frame read else [(False, None)]\n",
    "    frames = [read[1] for read in reads if read[0]]\n",
    "    rets = [read[0] for read in reads]\n",
    "\n",
    "    # os.makedirs(\"./runs/detect/predict/og/\")\n",
    "    # frames_to_detect = list(frames.copy())\n",
    "\n",
    "    det = detection(frames)\n",
    "    mean_bboxes = mean_bbox(det)\n",
    "\n",
    "    # mean_bboxes = det\n",
    "\n",
    "    for i in range(len(frames)):\n",
    "        if rets[i]:\n",
    "            # os.makedirs(\"./runs/detect/predict/og_f%d/\" % i)\n",
    "            # cv2.imwrite(\"./runs/detect/predict/og_f%d/image.jpg\" %i, frames[i])\n",
    "\n",
    "            drew_frame = frames[i].copy()\n",
    "\n",
    "\n",
    "            for j in range(len(mean_bboxes)):\n",
    "                # print(mean_bboxes[i][j])\n",
    "                xyxy = mean_bboxes[j][\"xyxy\"][0].astype(int).tolist()\n",
    "\n",
    "                cropped = Image.fromarray(cv2.cvtColor(frames[i], cv2.COLOR_BGR2RGB)).crop(xyxy)\n",
    "                # cropped.save(f\"./runs/detect/predict/og_f{i}/cropped{j}.jpg\")\n",
    "\n",
    "                fv = siamese_net.fv_encoding(cropped).cpu()\n",
    "\n",
    "                track_id = None\n",
    "                if features.empty:\n",
    "                    color = np.random.randint(0,255,3).tolist()\n",
    "                    features = pd.concat([features, pd.DataFrame({\"features\": [fv], \"color\": [color]})], ignore_index=True)\n",
    "                    track_id = features.index[-1]\n",
    "                    # print(\"FIRST: => \", track_id, \"\\n\")\n",
    "                else:\n",
    "                    similarities = pd.DataFrame(columns=[\"track_id\", \"prob\"])\n",
    "\n",
    "                    for id, row in features.iterrows():\n",
    "                        prob = siamese_net.similarity(cropped, row[\"features\"]).data[0].cpu().numpy()\n",
    "                        # print(prob)\n",
    "\n",
    "                        similarities = pd.concat([similarities, pd.DataFrame({\"track_id\": id, \"prob\": prob})], ignore_index=True)\n",
    "\n",
    "                    # print(\"SIMILARITIES: \\n\", similarities, \"\\n\", similarities[\"prob\"].idxmax(), \"\\n\", similarities.loc[similarities[\"prob\"].idxmax()])\n",
    "\n",
    "                    track_id = similarities.loc[similarities[\"prob\"].idxmax()][\"track_id\"]\n",
    "                    # print(similarities)\n",
    "\n",
    "                    if similarities.loc[track_id][\"prob\"] > 0.85: # nel caso aggiorniamo le features con quelle nuove trovate?\n",
    "                        features.loc[track_id][\"features\"] = fv\n",
    "                        color = features.loc[track_id][\"color\"]\n",
    "                        # print(\"TROVATO:  ==> \", track_id, \"\\n\")\n",
    "                        # display(cropped)\n",
    "                        # print(similarities.iloc[track_id][\"prob\"])\n",
    "                    else:\n",
    "                        color = np.random.randint(0,255,3).tolist()\n",
    "                        features = pd.concat([features, pd.DataFrame({\"features\": [fv], \"color\": [color]})], ignore_index=True)\n",
    "                        track_id = features.index[-1]\n",
    "                        # print(\"NUOVO: => \", track_id, \"\\n\")\n",
    "                    # print(df, \"\\n\")\n",
    "\n",
    "                # print(xyxy)\n",
    "                # print(color)\n",
    "                drew_frame = cv2.rectangle(drew_frame, (xyxy[0], xyxy[1]), (xyxy[2], xyxy[3]), color, 3)\n",
    "                drew_frame = cv2.putText(drew_frame, str(track_id), (xyxy[0], xyxy[1]), cv2.FONT_HERSHEY_SIMPLEX, 1.5, color, 2, cv2.LINE_AA)\n",
    "\n",
    "                print(type(drew_frame))\n",
    "            # cv2.imwrite(f\"./prova/img_r{round}_f{i}.jpg\", drew_frame)\n",
    "            # video_out.write(drew_frame.copy())\n",
    "\n",
    "    # os.rename(\"./runs/detect/predict\", \"./runs/detect/predict%d\" % round)\n",
    "\n",
    "    round += 1\n",
    "\n",
    "    if rets[2]:\n",
    "        # cv2.imshow(window_name, frame)\n",
    "        if cv2.waitKey(delay) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "video_out.release()\n",
    "# cv2.destroyWindow(window_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./runs2/detect/predict4/og/image%d.jpg\"\n",
    "frames = [Image.open(path % 0), Image.open(path % 1), Image.open(path % 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'detection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[35], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m----> 2\u001B[0m det \u001B[38;5;241m=\u001B[39m \u001B[43mdetection\u001B[49m(frames)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start)\n\u001B[1;32m      6\u001B[0m det\n",
      "\u001B[0;31mNameError\u001B[0m: name 'detection' is not defined"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "det = detection(frames)\n",
    "\n",
    "print(time.time() - start)\n",
    "\n",
    "det"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "9"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([np.gcd(i, 207) for i in range(5, 10)]).max()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, None, None, None, None, None, None, None]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[5, 6, 7, 8, 9, 5, 6, 7, 8, 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": "[10, 11, 12, 13, 14, 10, 11, 12, 13, 14]"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [None] * 10\n",
    "\n",
    "print(a)\n",
    "\n",
    "a[0:10] = np.arange(0, 10)\n",
    "\n",
    "print(a)\n",
    "\n",
    "a[:5] = a[5:]\n",
    "\n",
    "print(a)\n",
    "a[5:10] = np.arange(10, 15)\n",
    "a[:5] = a[5:]\n",
    "\n",
    "# a[5:10] = np.arange(15, 20)\n",
    "\n",
    "a"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "sklearn.cluster._kmeans.KMeans"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=3, random_state=0, n_init=\"auto\")\n",
    "type(kmeans)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('siv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c9c71ba83d9509be3e641d0bfc3c2b4ff64c3d1f38dab0db17242b2063feac14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
