{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from model.SiameseReId import SiameseReId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8s.pt\") # COCO128 classes https://github.com/ultralytics/yolov5/blob/master/data/coco128.yaml\n",
    "# model = YOLO(\"yolov8n-seg.pt\")\n",
    "siamese_net = SiameseReId(os.path.join('model','weights','model_final.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def detection(frames: np.array, should_save: bool = False) -> dict:\n",
    "    results = model(deepcopy(frames), save=should_save)\n",
    "    detected = {}\n",
    "\n",
    "    for frame in range(len(results)):\n",
    "        # print(frame, results[frame].boxes.numpy(), results[frame].boxes.cls)\n",
    "        boxes = results[frame].boxes\n",
    "        detected[frame] = []\n",
    "        for box in boxes:\n",
    "            box = box.numpy()\n",
    "            # print(box, box.cls, box.conf)\n",
    "            if int(box.cls[0]) == 0 and box.conf[0] > 0.5:\n",
    "                detected[frame].append({\n",
    "                    \"xyxy\": box.xyxy,\n",
    "                    \"xywh\": box.xywh,\n",
    "                    \"conf\": box.conf[0],\n",
    "                    \"center\": box.xywh[0][0:2]\n",
    "                })\n",
    "        # print('\\n')\n",
    "    return detected"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def distance(point1: np.array, point2: np.array) -> float:\n",
    "    return np.linalg.norm(point1 - point2)\n",
    "\n",
    "def is_closer_enough(dist: float, epsilon: float = 30) -> bool:\n",
    "    return dist <= epsilon"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def mean_bbox(frames: dict) -> dict:\n",
    "    same_bb = []\n",
    "    mean_bb = []\n",
    "\n",
    "    if len(frames) > 1:\n",
    "        for bbox0 in frames[0]: # bbox nel frame 0\n",
    "            same_bb.append([])\n",
    "            same_bb[-1].append(bbox0)\n",
    "            # print(same_bbox)\n",
    "            # print(\"0: \", bbox0[\"center\"])\n",
    "\n",
    "            for bbox1 in frames[1]: # bbox nel frame 1\n",
    "                # print(\"\\t1: \", bbox1[\"center\"], \"DIST: \", distance(bbox0[\"center\"], bbox1[\"center\"]))\n",
    "                if is_closer_enough(distance(bbox0[\"center\"], bbox1[\"center\"])): # bbox0 <-> bbox1\n",
    "                    same_bb[-1].append(bbox1)\n",
    "                    # print(\"FOUND IT \\t1: \", bbox1[\"center\"])\n",
    "\n",
    "            for bbox2 in frames[2]: # bbox nel frame 2\n",
    "                # print(\"\\t2: \", bbox2[\"center\"], \"DIST: \", distance(same_bbox[-1][-1][\"center\"], bbox2[\"center\"]))\n",
    "                if is_closer_enough(distance(same_bb[-1][-1][\"center\"], bbox2[\"center\"])): # (bbox1 or bbox0) <-> bbox2\n",
    "                    same_bb[-1].append(bbox2)\n",
    "                    # print(\"FOUND IT \\t2: \", bbox2[\"center\"])\n",
    "\n",
    "        for bboxes in same_bb:\n",
    "            bbs = {\n",
    "                \"xyxy\": np.mean(np.array([frame[\"xyxy\"] for frame in bboxes]), axis=0),\n",
    "                \"xywh\": np.mean(np.array([frame[\"xywh\"] for frame in bboxes]), axis=0),\n",
    "                \"conf\": np.mean(np.array([frame[\"conf\"] for frame in bboxes])),\n",
    "                \"center\": np.mean(np.array([frame[\"center\"] for frame in bboxes]), axis=0),\n",
    "            }\n",
    "            # print([frame[\"xyxy\"] for frame in bboxes])\n",
    "            # mean_bb.append(np.mean(np.array([frame[\"xyxy\"] for frame in bboxes]), axis=0))\n",
    "            mean_bb.append(bbs)\n",
    "    else:\n",
    "        for bbox0 in frames[0]:\n",
    "            mean_bb.append({\n",
    "                \"xyxy\": bbox0[\"xyxy\"],\n",
    "                \"xywh\": bbox0[\"xywh\"],\n",
    "                \"conf\": bbox0[\"conf\"],\n",
    "                \"center\": bbox0[\"center\"],\n",
    "            })\n",
    "\n",
    "    return mean_bb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_path = 'test.mp4'\n",
    "delay = 1\n",
    "window_name = 'frame'\n",
    "\n",
    "cap = cv2.VideoCapture(file_path)\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    sys.exit()\n",
    "\n",
    "count = 3\n",
    "# frames = []\n",
    "round = 0\n",
    "\n",
    "video_out = cv2.VideoWriter(\"./video_output.mp4\", cv2.VideoWriter_fourcc(*'DIVX'), int(cap.get(cv2.CAP_PROP_FPS)), (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "features = pd.DataFrame(columns=[\"features\"])\n",
    "# similarities = pd.DataFrame(columns=[\"track_id\", \"prob\"])\n",
    "\n",
    "while round < 10:\n",
    "# while True:\n",
    "    reads = [cap.read() for i in range(count)] # [(True, [...]] if frame read else [(False, None)]\n",
    "    frames = [read[1] for read in reads if read[0]]\n",
    "    rets = [read[0] for read in reads]\n",
    "\n",
    "    # os.makedirs(\"./runs/detect/predict/og/\")\n",
    "    # frames_to_detect = list(frames.copy())\n",
    "\n",
    "    det = detection(frames)\n",
    "    mean_bboxes = mean_bbox(det)\n",
    "\n",
    "    # mean_bboxes = det\n",
    "\n",
    "    for i in range(len(frames)):\n",
    "        if rets[i]:\n",
    "            # os.makedirs(\"./runs/detect/predict/og_f%d/\" % i)\n",
    "            # cv2.imwrite(\"./runs/detect/predict/og_f%d/image.jpg\" %i, frames[i])\n",
    "\n",
    "            drew_frame = frames[i].copy()\n",
    "\n",
    "            for j in range(len(mean_bboxes)):\n",
    "                # print(mean_bboxes[i][j])\n",
    "                xyxy = mean_bboxes[j][\"xyxy\"][0].astype(int).tolist()\n",
    "                cropped = Image.fromarray(cv2.cvtColor(frames[i], cv2.COLOR_BGR2RGB)).crop(xyxy)\n",
    "                # cropped.save(f\"./runs/detect/predict/og_f{i}/cropped{j}.jpg\")\n",
    "\n",
    "                fv = siamese_net.fv_encoding(cropped)\n",
    "\n",
    "                track_id = None\n",
    "                if features.empty:\n",
    "                    features = pd.concat([features, pd.DataFrame({\"features\": [fv]})], ignore_index=True)\n",
    "                    track_id = features.index[-1]\n",
    "                    # print(\"FIRST: => \", track_id, \"\\n\")\n",
    "                else:\n",
    "                    similarities = pd.DataFrame(columns=[\"track_id\", \"prob\"])\n",
    "\n",
    "                    for id, row in features.iterrows():\n",
    "                        prob = siamese_net.similarity(cropped, row[\"features\"]).data[0].numpy()\n",
    "                        # print(prob)\n",
    "\n",
    "                        similarities = pd.concat([similarities, pd.DataFrame({\"track_id\": id, \"prob\": prob})], ignore_index=True)\n",
    "\n",
    "                    # print(\"SIMILARITIES: \\n\", similarities, \"\\n\", similarities[\"prob\"].idxmax(), \"\\n\", similarities.loc[similarities[\"prob\"].idxmax()])\n",
    "\n",
    "                    track_id = similarities.loc[similarities[\"prob\"].idxmax()][\"track_id\"]\n",
    "\n",
    "                    if similarities.loc[track_id][\"prob\"] > 0.8: # nel caso aggiorniamo le features con quelle nuove trovate?\n",
    "                        print(\"TROVATO:  ==> \", track_id, \"\\n\")\n",
    "                        # display(cropped)\n",
    "                        # print(similarities.iloc[track_id][\"prob\"])\n",
    "                    else:\n",
    "                        features = pd.concat([features, pd.DataFrame({\"features\": [fv]})], ignore_index=True)\n",
    "                        track_id = features.index[-1]\n",
    "                        # print(\"NUOVO: => \", track_id, \"\\n\")\n",
    "                    # print(df, \"\\n\")\n",
    "\n",
    "                # print(xyxy)\n",
    "                drew_frame = cv2.rectangle(drew_frame, (xyxy[0], xyxy[1]), (xyxy[2], xyxy[3]), (255,0,0), 3)\n",
    "                drew_frame = cv2.putText(drew_frame, str(track_id), (xyxy[0], xyxy[1]), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            cv2.imwrite(f\"./prova/img_r{round}_f{i}.jpg\", drew_frame)\n",
    "            video_out.write(drew_frame)\n",
    "\n",
    "    # os.rename(\"./runs/detect/predict\", \"./runs/detect/predict%d\" % round)\n",
    "\n",
    "    round += 1\n",
    "\n",
    "    if rets[2]:\n",
    "        # cv2.imshow(window_name, frame)\n",
    "        if cv2.waitKey(delay) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "video_out.release()\n",
    "cv2.destroyWindow(window_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('siv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c9c71ba83d9509be3e641d0bfc3c2b4ff64c3d1f38dab0db17242b2063feac14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
