{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riccardo/anaconda3/envs/siv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('people_test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.24 ðŸš€ Python-3.9.16 torch-1.13.1+cu117 CPU\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "0: 256x640 6 persons, 109.2ms\n",
      "Speed: 1.1ms pre-process, 109.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model(image, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
       " type: <class 'torch.Tensor'>\n",
       " shape: torch.Size([6, 6])\n",
       " dtype: torch.float32\n",
       "  + tensor([[9.90000e+01, 5.00000e+00, 3.18000e+02, 3.83000e+02, 9.19241e-01, 0.00000e+00],\n",
       "         [3.07000e+02, 6.50000e+01, 4.40000e+02, 3.85000e+02, 8.73961e-01, 0.00000e+00],\n",
       "         [7.40000e+02, 5.40000e+01, 9.46000e+02, 3.87000e+02, 8.54227e-01, 0.00000e+00],\n",
       "         [4.07000e+02, 5.40000e+01, 6.00000e+02, 3.86000e+02, 8.24071e-01, 0.00000e+00],\n",
       "         [6.62000e+02, 2.90000e+01, 7.96000e+02, 3.83000e+02, 7.77543e-01, 0.00000e+00],\n",
       "         [5.43000e+02, 6.00000e+01, 6.52000e+02, 3.82000e+02, 7.09505e-01, 0.00000e+00]])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"features\"])\n",
    "\n",
    "print(df)\n",
    "\n",
    "detections = np.random.randint(100, size=4)\n",
    "print(\"Images: \", detections, \"\\n\")\n",
    "\n",
    "for det in detections:\n",
    "    similarities = pd.DataFrame(columns=[\"track_id\", \"prob\"])\n",
    "    print(\"Detected image: \", det, \"\\n\")\n",
    "\n",
    "    vector = np.random.randint(100, size=4) # torch.model.densnet1(det) dall'immagine estrapolo il feature vector\n",
    "\n",
    "    if df.empty:\n",
    "        # vector = np.random.randint(100, size=4) # torch.model.densnet1(det) dall'immagine estrapolo il feature vector\n",
    "        df = pd.concat([df, pd.DataFrame({\"features\": [vector]})], ignore_index=True) # salvo il feature vector\n",
    "        print(\"Primo inserimento Dataframe: \\n\", df)\n",
    "    else:\n",
    "        # vector =  np.random.randint(100, size=4) # torch.model.densnet1(det\n",
    "        for id, row in df.iterrows(): # da ottimizzare con vec o vec_numpy o apply\n",
    "            prob = np.random.rand(1,1)[0] # snn_model(row, det)\n",
    "            similarities = pd.concat([similarities, pd.DataFrame({\"track_id\": id, \"prob\": prob})], ignore_index=True)\n",
    "            print(similarities, \"\\n\")\n",
    "\n",
    "        # print(similarities[\"prob\"].max(), similarities[\"prob\"].idxmax())\n",
    "        track_id = similarities[\"prob\"].idxmax()\n",
    "\n",
    "        if similarities.iloc[track_id][\"prob\"] > 0.9: # nel caso aggiorniamo le features con quelle nuove trovate?\n",
    "            print(\"TROVATO: \", det, \" ==> \", track_id, \"\\n\")\n",
    "        # print(similarities.iloc[track_id][\"features\"])\n",
    "        else:\n",
    "            df = pd.concat([df, pd.DataFrame({\"features\": [vector]})], ignore_index=True)\n",
    "        print(df, \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('siv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c9c71ba83d9509be3e641d0bfc3c2b4ff64c3d1f38dab0db17242b2063feac14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
